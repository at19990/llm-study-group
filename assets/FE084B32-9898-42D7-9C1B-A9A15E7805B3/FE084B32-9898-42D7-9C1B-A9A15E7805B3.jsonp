local_slide( {"name":"FE084B32-9898-42D7-9C1B-A9A15E7805B3","json":{"assets":{"BC3E7DFBD1F82DA94BF09C7CA038F639":{"type":"texture","index":0,"assetRequest":{"type":"slide","state":"contents","slide":"none"},"url":{"native":"assets\/FE084B32-9898-42D7-9C1B-A9A15E7805B3.pdf"},"width":1920,"height":1080},"C67333CBCB5067D360A349EBD09260C0":{"type":"texture","index":1,"assetRequest":{"type":"slide","state":"contents","slide":"none"},"url":{"native":"assets\/FE084B32-9898-42D7-9C1B-A9A15E7805B3.pdf"},"width":1920,"height":1080}},"events":[{"effects":[{"beginTime":0,"baseLayer":{"animations":[],"initialState":{"affineTransform":[1,0,0,1,0,0],"masksToBounds":false,"rotation":0,"scale":1,"position":{"pointX":960,"pointY":540},"width":1920,"sublayerTransform":[1,0,0,0,0,1,0,0,0,0,1,0,0,0,0,1],"contentsRect":{"y":0,"x":0,"width":1,"height":1},"opacity":1,"edgeAntialiasingMask":251658240,"height":1080,"hidden":false,"anchorPoint":{"pointX":0.5,"pointY":0.5}},"objectID":"0","layers":[{"animations":[],"initialState":{"affineTransform":[1,0,0,1,0,0],"masksToBounds":false,"rotation":0,"scale":1,"position":{"pointX":960,"pointY":540},"width":1920,"sublayerTransform":[1,0,0,0,0,1,0,0,0,0,1,-0.00035007912466775983,0,0,0,1],"contentsRect":{"y":0,"x":0,"width":1,"height":1},"opacity":1,"edgeAntialiasingMask":251658240,"height":1080,"hidden":false,"anchorPoint":{"pointX":0.5,"pointY":0.5}},"layers":[{"animations":[],"layers":[],"texturedRectangle":{"isBackgroundTexture":false,"singleTextureOpacity":1,"textureType":0,"textBaseline":0,"textXHeight":0,"isVerticalText":false},"initialState":{"affineTransform":[1,0,0,1,0,0],"masksToBounds":false,"rotation":0,"scale":1,"position":{"pointX":960,"pointY":540},"width":1920,"sublayerTransform":[1,0,0,0,0,1,0,0,0,0,1,0,0,0,0,1],"contentsRect":{"y":0,"x":0,"width":1,"height":1},"opacity":1,"edgeAntialiasingMask":0,"height":1080,"hidden":false,"anchorPoint":{"pointX":0.5,"pointY":0.5}},"texture":"C67333CBCB5067D360A349EBD09260C0"},{"animations":[{"additive":false,"timeOffset":0,"beginTime":0,"from":{"scalar":false},"repeatCount":0,"fillMode":"both","duration":0.01,"autoreverses":false,"property":"hidden","to":{"scalar":true},"removedOnCompletion":false}],"layers":[],"texturedRectangle":{"isBackgroundTexture":false,"singleTextureOpacity":1,"textureType":0,"textBaseline":0,"textXHeight":0,"isVerticalText":false},"initialState":{"affineTransform":[1,0,0,1,0,0],"masksToBounds":false,"rotation":0,"scale":1,"position":{"pointX":960,"pointY":540},"width":1920,"sublayerTransform":[1,0,0,0,0,1,0,0,0,0,1,0,0,0,0,1],"contentsRect":{"y":0,"x":0,"width":1,"height":1},"opacity":1,"edgeAntialiasingMask":0,"height":1080,"hidden":false,"anchorPoint":{"pointX":0.5,"pointY":0.5}},"texture":"BC3E7DFBD1F82DA94BF09C7CA038F639"}]}]},"effects":[],"duration":0.01,"type":"transition","attributes":{"direction":0},"name":"none","objectID":"0"}],"automaticPlay":false,"hyperlinks":[],"accessibility":[{"text":"パラメータ効率の良いチューニング方法","targetRectangle":{"y":126.84375,"x":138.625,"width":1505.28,"height":83.999914884567261}},{"text":"LLMは膨大なパラメータを持つため、推論に必要なメモリ量が莫大","targetRectangle":{"y":283.25839233398438,"x":123.02466201782227,"width":1472.7327999999995,"height":67}},{"text":"モデルを圧縮することでメモリ使用を削減できる","targetRectangle":{"y":348.09844386577606,"x":158.02466201782227,"width":1081.6959999999997,"height":84.55994987487793}},{"text":"圧縮の方法として一般的には「量子化」が行われる","targetRectangle":{"y":437.554464825629,"x":123.02466201782227,"width":1130.4831999999997,"height":84.55994987487793}},{"text":"量子化とは、浮動小数店からビット数の小さい整数にモデルのパラメータやアクティベーション (中間層) の値を変換して圧縮すること","targetRectangle":{"y":527.01048578548193,"x":158.02466201782227,"width":1669.1135999999999,"height":156.45602095985294}},{"text":"量子化を考慮した学習 (QAT) と学習後の量子化 (PTQ) があるが、後者の方が計算コストがはるかに低い","targetRectangle":{"y":681.30655827712656,"x":158.02466201782227,"width":1641.0240000000001,"height":149.40000140666962}},{"text":"LLMは小さい言語モデルよりも量子化の影響を受けにくく、同じメモリコストであれば小さなモデルよりも量子化した大きなモデルを使用する方が良い","targetRectangle":{"y":835.60263076877118,"x":158.02466201782227,"width":1670.5920000000001,"height":149.40000140666962}}],"baseLayer":{"animations":[],"initialState":{"affineTransform":[1,0,0,1,0,0],"masksToBounds":false,"rotation":0,"scale":1,"position":{"pointX":960,"pointY":540},"width":1920,"sublayerTransform":[1,0,0,0,0,1,0,0,0,0,1,0,0,0,0,1],"contentsRect":{"y":0,"x":0,"width":1,"height":1},"opacity":1,"edgeAntialiasingMask":251658240,"height":1080,"hidden":false,"anchorPoint":{"pointX":0.5,"pointY":0.5}},"objectID":"0","layers":[{"animations":[],"initialState":{"affineTransform":[1,0,0,1,0,0],"masksToBounds":false,"rotation":0,"scale":1,"position":{"pointX":960,"pointY":540},"width":1920,"sublayerTransform":[1,0,0,0,0,1,0,0,0,0,1,-0.00035007912466775983,0,0,0,1],"contentsRect":{"y":0,"x":0,"width":1,"height":1},"opacity":1,"edgeAntialiasingMask":251658240,"height":1080,"hidden":false,"anchorPoint":{"pointX":0.5,"pointY":0.5}},"layers":[{"animations":[],"layers":[],"texturedRectangle":{"isBackgroundTexture":false,"singleTextureOpacity":1,"textureType":0,"textBaseline":0,"textXHeight":0,"isVerticalText":false},"initialState":{"affineTransform":[1,0,0,1,0,0],"masksToBounds":false,"rotation":0,"scale":1,"position":{"pointX":960,"pointY":540},"width":1920,"sublayerTransform":[1,0,0,0,0,1,0,0,0,0,1,0,0,0,0,1],"contentsRect":{"y":0,"x":0,"width":1,"height":1},"opacity":1,"edgeAntialiasingMask":0,"height":1080,"hidden":false,"anchorPoint":{"pointX":0.5,"pointY":0.5}},"texture":"BC3E7DFBD1F82DA94BF09C7CA038F639"}]}]}}]}} )